{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/pytorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-30 04:53:11.536077: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from transformers import T5Model, T5Tokenizer\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import request_with_prompt, request_with_prompt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** T5Tokenizition Begins.***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 6515/6515 [03:54<00:00, 27.73it/s]\n",
      "/home/max/miniconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** T5Tokenizition Done. Begin Clustering ***\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer\n",
    "print('*** T5Tokenizition Begins.***')\n",
    "ptm_path = \"t5-small\"\n",
    "model = T5Model.from_pretrained(ptm_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(ptm_path)\n",
    "\n",
    "path = \"data/nq-dev.json\"\n",
    "data = json.load(open(path, \"r\"))\n",
    "\n",
    "pairs = []\n",
    "for line in data:\n",
    "    pairs.append((line[\"question\"], line[\"positive_ctxs\"][0][\"text\"]))\n",
    "\n",
    "embeddings = []\n",
    "for qc_index in tqdm(range(len(pairs))):\n",
    "    q = pairs[qc_index][0]\n",
    "    c = pairs[qc_index][1]\n",
    "    text = q + \" \" + c\n",
    "    encoded = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "    output = model(input_ids=encoded[\"input_ids\"],\n",
    "                   attention_mask=encoded[\"attention_mask\"],\n",
    "                   decoder_input_ids=encoded[\"input_ids\"]\n",
    "                  )[0] # 1, seq_len, hidden_size\n",
    "    embeddings.append(output[0].mean(dim=0).detach().numpy())\n",
    "\n",
    "\n",
    "print('*** T5Tokenizition Done. Begin Clustering ***')\n",
    "n_clusters = 5\n",
    "results = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(np.array(embeddings)).tolist()\n",
    "\n",
    "\n",
    "cluster_results = defaultdict(list)\n",
    "for qc, k in zip(pairs, results):\n",
    "    q = qc[0]\n",
    "    c = qc[1]\n",
    "    cluster_results[k].append((q, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6515/6515 [00:05<00:00, 1263.29it/s]\n"
     ]
    }
   ],
   "source": [
    "questions = [ q for q,c in pairs]\n",
    "\n",
    "all_prompt_list = []\n",
    "for q_index in tqdm(range(len(questions))):\n",
    "    sample_q = questions[q_index]\n",
    "    generated_contexts = []\n",
    "    prompts_list = []\n",
    "    for k, v in cluster_results.items():\n",
    "        random.shuffle(v)\n",
    "        prompt = \"\"\n",
    "        for q,c in v[:5]:\n",
    "            prompt += q + \" \" + c\n",
    "        \n",
    "        prompt += \" \" + sample_q\n",
    "        prompts_list.append(prompt)\n",
    "    \n",
    "    all_prompt_list.append(prompts_list)\n",
    "     \n",
    "\n",
    "        #generated_contexts.append(executor.submit(request_with_prompt, prompt))\n",
    "        #output = request_with_prompt(prompt=prompt)\n",
    "        #generated_contexts.append(output)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=25) as executor:\n",
    "    for output in executor.map(request_with_prompt_batch, all_prompt_list):\n",
    "         generated_contexts.append(output)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "json_object = json.dumps(generated_contexts, indent=4)\n",
    "with open(\"generated_ctxs.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "    #print('successfully generated for prompt for:' ,q_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2000 = '/home/max/research/genQA/NLP/gen_then_read/generated_ctxs.json'\n",
    "path_2000_p = '/home/max/research/genQA/NLP/gen_then_read/generated_ctxs_2000+.json'\n",
    "ctx_2000 = json.load(open(path_2000, \"r\"))\n",
    "ctx_2000p = json.load(open(path_2000_p,\"r\"))\n",
    "ctx_all = ctx_2000 +ctx_2000p\n",
    "ctx_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6515/6515 [00:00<00:00, 68434.49it/s]\n"
     ]
    }
   ],
   "source": [
    "generated_data = []\n",
    "questions = [ q for q,c in pairs]\n",
    "for q_index in tqdm(range(len(ctx_all))):\n",
    "    sample_q = questions[q_index]\n",
    "    ctxs_dict = {}\n",
    "    #ctxs_list = generated_contexts[q_index]\n",
    "    ctxs_list = ctx_all[q_index]\n",
    "    all_ctxs = []\n",
    "    for ctx in ctxs_list:\n",
    "        ctxs_dict = {}\n",
    "        if len(ctx) > 0:\n",
    "            ctxs_dict['title'] = random.choice(ctx.split())\n",
    "        else:\n",
    "            ctxs_dict['title'] = 'NA'\n",
    "        ctxs_dict['text'] = ctx\n",
    "        all_ctxs.append(ctxs_dict)\n",
    "    \n",
    "    \n",
    "    answers = data[q_index]['answers']\n",
    "    \n",
    "    target = random.choice(answers)\n",
    "    generated_data.append(\n",
    "        {\n",
    "            \"question\": sample_q,\n",
    "            'target': target,\n",
    "            'answers': answers, \n",
    "            \"ctxs\": all_ctxs\n",
    "            }\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_object = json.dumps(x_test, indent=4)\n",
    "with open(\"nq_gpt_ctxs_mean_cluster_test_large.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_object = json.dumps(x_train, indent=4)\n",
    "with open(\"nq_gpt_ctxs_mean_cluster_train_large.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
